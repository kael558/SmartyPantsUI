{"id":"b7ebf8e7-688c-48f2-ac7c-aaaa55da0ed6","data":{"nodes":[{"data":{"description":"Create a prompt template with dynamic variables.","display_name":"Prompt","id":"Prompt-1BZdB","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"You are a helpful assistant proficient in React and CSS. Your task is to update a given React component and its associated stylesheet based on a requested change. Please follow these instructions carefully:\n\n1. Input Details:\n- React Component File: A file containing the code of a React component written in either JSX or TSX.\n- Stylesheet: A CSS file associated with the React component.\n- Requested Change: A specific change that needs to be made to the text content in the React component.\n\n2. Output Requirements:\n- Updated React Component File: Provide the entire updated code of the React component, ensuring that the requested text change is applied.\n- Updated Stylesheet: Provide the entire updated stylesheet if there are any changes required based on the text modification.\n\n\n3. Guidelines:\n- Maintain the format (JSX or TSX) as provided in the original component file.\n- Make sure that the entire code and CSS are provided, not just the parts that were changed.\n- Use the provided separators to clearly denote the JSX and CSS files in your response.\n\n4. Example Input\n# REACT COMPONENT\n```jsx\nimport React from 'react';\nimport './Component.css';\n\n\nconst Component = () => {{ return (<div className=\"container\"><h1>Hello World!</h1></div>);}};\nexport default Component;\n```\n\n# STYLESHEET\n```css\n.container {{ text-align: center; color: blue; }}\n```\n\n# REQUESTED CHANGE\nChange the heading text from \"Hello, World!\" to \"Welcome to React!\".\n\n\n5. Example Output\n# UPDATED REACT COMPONENT\n```jsx\nimport React from 'react';\nimport './Component.css';\n\nconst Component = () => {{ return (<div className=\"container\"><h1>Welcome to React!</h1></div>);}};\n\nexport default Component;\n```\n\n# UPDATED STYLESHEET\n```css\n.container {{ text-align: center; color: blue;}}\n```\n\n6. Input\n# REACT COMPONENT\n```jsx\n{component}\n```\n\n# STYLESHEET\n```css\n{stylesheet}\n```\n\n# REQUESTED CHANGE\n{requested_change}\n\n\n","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt","load_from_db":false},"component":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"component","display_name":"component","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"stylesheet":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"stylesheet","display_name":"stylesheet","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"requested_change":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"requested_change","display_name":"requested_change","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["component","stylesheet","requested_change"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":false,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"type":"Prompt"},"dragging":false,"height":607,"id":"Prompt-1BZdB","position":{"x":11.949972296758347,"y":1045.080341450528},"positionAbsolute":{"x":11.949972296758347,"y":1045.080341450528},"selected":false,"type":"genericNode","width":384},{"data":{"id":"OpenAIModel-HgWk3","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-4o","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"type":"OpenAIModel","description":"Generates text using OpenAI LLMs.","display_name":"OpenAI"},"dragging":false,"height":619,"id":"OpenAIModel-HgWk3","position":{"x":672.8183826229746,"y":1217.5616340620422},"positionAbsolute":{"x":672.8183826229746,"y":1217.5616340620422},"selected":false,"type":"genericNode","width":384},{"id":"TextInput-YlzsL","type":"genericNode","position":{"x":-782.2373372311545,"y":1032.7092587610798},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"requested_change","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextInput-YlzsL"},"selected":true,"width":384,"height":307,"positionAbsolute":{"x":-782.2373372311545,"y":1032.7092587610798},"dragging":false},{"id":"TextInput-PB9Pc","type":"genericNode","position":{"x":-779.3436135619922,"y":715.2001703014952},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"component","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextInput-PB9Pc"},"selected":false,"width":384,"height":307,"dragging":false,"positionAbsolute":{"x":-779.3436135619922,"y":715.2001703014952}},{"id":"TextInput-wJ4wa","type":"genericNode","position":{"x":-767.1325027726313,"y":1405.682980390821},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"stylesheet","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextInput-wJ4wa","description":"Get text inputs from the Playground.","display_name":"stylesheet"},"selected":false,"width":384,"height":307,"positionAbsolute":{"x":-767.1325027726313,"y":1405.682980390821},"dragging":false},{"id":"TextOutput-iPRLn","type":"genericNode","position":{"x":1233.269464720882,"y":1333.5264166355055},"data":{"type":"TextOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"updated_code","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextOutput-iPRLn"},"selected":false,"width":384,"height":307,"positionAbsolute":{"x":1233.269464720882,"y":1333.5264166355055},"dragging":false}],"edges":[{"data":{"sourceHandle":{"dataType":"Prompt","id":"Prompt-1BZdB","name":"prompt","output_types":["Message"]},"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-HgWk3","inputTypes":["Message"],"type":"str"}},"id":"reactflow__edge-Prompt-1BZdB{œdataTypeœ:œPromptœ,œidœ:œPrompt-1BZdBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-HgWk3{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-HgWk3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","source":"Prompt-1BZdB","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-1BZdBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"OpenAIModel-HgWk3","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-HgWk3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-wJ4wa","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-wJ4waœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-1BZdB","targetHandle":"{œfieldNameœ:œstylesheetœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"stylesheet","id":"Prompt-1BZdB","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-wJ4wa","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-wJ4wa{œdataTypeœ:œTextInputœ,œidœ:œTextInput-wJ4waœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-1BZdB{œfieldNameœ:œstylesheetœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-YlzsL","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YlzsLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-1BZdB","targetHandle":"{œfieldNameœ:œrequested_changeœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"requested_change","id":"Prompt-1BZdB","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-YlzsL","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-YlzsL{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YlzsLœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-1BZdB{œfieldNameœ:œrequested_changeœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-PB9Pc","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-PB9Pcœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-1BZdB","targetHandle":"{œfieldNameœ:œcomponentœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"component","id":"Prompt-1BZdB","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-PB9Pc","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-PB9Pc{œdataTypeœ:œTextInputœ,œidœ:œTextInput-PB9Pcœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-1BZdB{œfieldNameœ:œcomponentœ,œidœ:œPrompt-1BZdBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-HgWk3","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HgWk3œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-iPRLn","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-iPRLnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-iPRLn","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-HgWk3","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-OpenAIModel-HgWk3{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HgWk3œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-iPRLn{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-iPRLnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":0,"y":0,"zoom":1}},"description":"Adjusts React component","name":"EditComponent","last_tested_version":"1.0.7","endpoint_name":"coder","is_component":false}